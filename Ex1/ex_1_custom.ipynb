{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import madmom\n",
    "import librosa\n",
    "import mir_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madmom.utils import search_files, match_file\n",
    "\n",
    "AUDIO_FILES = search_files('data/train', '.flac')\n",
    "\n",
    "def find_audio_files(ann_files, audio_files, ann_suffix=None, audio_suffix='.wav'):\n",
    "    \"\"\"\n",
    "    Find matching audio files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ann_files : list\n",
    "        List with annotation file names.\n",
    "    audio_files : list\n",
    "        List with audio file names to be matched\n",
    "    ann_suffix : str, optional\n",
    "        Suffix of the annotation files. If 'None'\n",
    "        the suffix is inferred from the annotation\n",
    "        files.\n",
    "    audio_suffix : str, optional\n",
    "        Suffix of the audio files.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    matched_files : list\n",
    "        List of matched audio file (names).\n",
    "    matched_indices : list\n",
    "        List of matching indices in `audio_files`.\n",
    "        \n",
    "    \"\"\"\n",
    "    matched_files = []\n",
    "    matched_indices = []\n",
    "    for i, ann_file in enumerate(ann_files):\n",
    "        if ann_suffix is None:\n",
    "            ann_suffix = os.path.splitext(ann_file)[1]\n",
    "        matches = match_file(ann_file, audio_files,\n",
    "                             ann_suffix, audio_suffix)\n",
    "        if len(matches) == 1:\n",
    "            matched_files.append(matches[0])\n",
    "            matched_indices.append(i)\n",
    "        else:\n",
    "            continue\n",
    "    return matched_files, matched_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM\n",
    "\n",
    "# len(AUDIO_FILES)\n",
    "\n",
    "# from scripts import utilities\n",
    "# utilities.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define additional constants\n",
    "SR = 44100 # samping rate\n",
    "FRAME_SIZE = 2048 # number of samples per frame\n",
    "HOP_SIZE = int(SR / FPS) # hop size depends on sampling rate and frame rate\n",
    "NUM_BANDS = 40 # number of mel bins\n",
    "\n",
    "def pre_process(filename, frame_size=2048, frame_rate=FPS, num_bands=40, **kwargs):\n",
    "    \"\"\"\n",
    "    Pre-process the audio signal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        File to be processed.\n",
    "    frame_size : int\n",
    "        Size of the frames.\n",
    "    frame_rate : float\n",
    "        Frame rate used for the STFT.\n",
    "    num_bands : int\n",
    "        Number of frequency bands for the Mel filterbank.\n",
    "    kwargs : dict, optional\n",
    "        Additional keyword arguments.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    spectrogram : numpy array\n",
    "        Spectrogram.\n",
    "\n",
    "    \"\"\"    \n",
    "    # STEP 1: read in audio\n",
    "    signal, sampling_rate_unused = librosa.load(filename, sr=SR) # read file\n",
    "    \n",
    "    # STEP 2,3: compute stft (default windowing function is Hann)\n",
    "    stft = librosa.core.stft(y=signal, n_fft=frame_size, hop_length=HOP_SIZE)\n",
    "    \n",
    "    # STEP 4: discard phase info and square magnitudes\n",
    "    initial_spectrogram = abs(stft)**2\n",
    "    \n",
    "    # STEP 5: apply mel scaling\n",
    "    mel_bins = librosa.filters.mel(sr=SR, n_fft=frame_size, n_mels=num_bands)\n",
    "    mel_spectrogram = mel_bins.dot(initial_spectrogram)\n",
    "    \n",
    "    # STEP 6: apply DB scaling\n",
    "    db_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
    "    \n",
    "    # double check\n",
    "    # mel_spectrogram = librosa.feature.melspectrogram(y=signal, sr=sr, n_fft=frame_size, hop_length=hop_size, n_mels=num_bands)\n",
    "    # db_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
    "    # print((db_mel_spectrogram)[0])\n",
    "        \n",
    "    spectrogram = db_mel_spectrogram\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM\n",
    "\n",
    "from librosa.display import specshow\n",
    "\n",
    "def test_pre_process():\n",
    "    texasName = AUDIO_FILES[19] #AUDIO_FILES[19]\n",
    "\n",
    "    spectrogram = pre_process(texasName, FRAME_SIZE, FPS, NUM_BANDS)\n",
    "\n",
    "    # print(spectrogram.shape)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    specshow(spectrogram, sr=SR, hop_length=HOP_SIZE, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "\n",
    "# test_pre_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for collecting pre-processed spectrograms\n",
    "# Note: it is not necessary to use this list but recommended in order to\n",
    "#       avoid recomputation of the same features over and over again.\n",
    "#       *_AUDIO_IDX canbe used to acces the precomputed spectrograms by\n",
    "#       index.\n",
    "SPECTROGRAMS = []\n",
    "\n",
    "for audio_file in AUDIO_FILES:\n",
    "    spec = pre_process(audio_file)\n",
    "    SPECTROGRAMS.append(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
