{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import madmom\n",
    "import librosa\n",
    "import mir_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madmom.utils import search_files, match_file\n",
    "\n",
    "AUDIO_FILES = search_files('data/train', '.flac')\n",
    "\n",
    "def find_audio_files(ann_files, audio_files, ann_suffix=None, audio_suffix='.wav'):\n",
    "    \"\"\"\n",
    "    Find matching audio files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ann_files : list\n",
    "        List with annotation file names.\n",
    "    audio_files : list\n",
    "        List with audio file names to be matched\n",
    "    ann_suffix : str, optional\n",
    "        Suffix of the annotation files. If 'None'\n",
    "        the suffix is inferred from the annotation\n",
    "        files.\n",
    "    audio_suffix : str, optional\n",
    "        Suffix of the audio files.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    matched_files : list\n",
    "        List of matched audio file (names).\n",
    "    matched_indices : list\n",
    "        List of matching indices in `audio_files`.\n",
    "        \n",
    "    \"\"\"\n",
    "    matched_files = []\n",
    "    matched_indices = []\n",
    "    for i, ann_file in enumerate(ann_files):\n",
    "        if ann_suffix is None:\n",
    "            ann_suffix = os.path.splitext(ann_file)[1]\n",
    "        matches = match_file(ann_file, audio_files,\n",
    "                             ann_suffix, audio_suffix)\n",
    "        if len(matches) == 1:\n",
    "            matched_files.append(matches[0])\n",
    "            matched_indices.append(i)\n",
    "        else:\n",
    "            continue\n",
    "    return matched_files, matched_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AUDIO_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main()\n",
      "sys.version_info(major=3, minor=7, micro=1, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "utilities.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def pre_process(filename, frame_size=2048, frame_rate=FPS, num_bands=40, **kwargs):\n",
    "    \"\"\"\n",
    "    Pre-process the audio signal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        File to be processed.\n",
    "    frame_size : int\n",
    "        Size of the frames.\n",
    "    frame_rate : float\n",
    "        Frame rate used for the STFT.\n",
    "    num_bands : int\n",
    "        Number of frequency bands for the Mel filterbank.\n",
    "    kwargs : dict, optional\n",
    "        Additional keyword arguments.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    spectrogram : numpy array\n",
    "        Spectrogram.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    signal, sr = librosa.load(filename, sr=44100)\n",
    "    \n",
    "    print(\"signal length:\", len(signal))\n",
    "    \n",
    "    hop_size = 441\n",
    "    \n",
    "    framesNeeded = math.trunc(len(signal) / hop_size)\n",
    "    \n",
    "    frontZeroPaddedSignal = np.concatenate((np.zeros(1024), signal))\n",
    "    endZeros = 2048 - (len(frontZeroPaddedSignal) - framesNeeded * hop_size)\n",
    "    print(\"end zeros:\", endZeros)\n",
    "    \n",
    "    paddedSignal = np.concatenate((frontZeroPaddedSignal, np.zeros(endZeros)))\n",
    "    print(\"padded signal length:\",len(paddedSignal))\n",
    "    \n",
    "    framesCustom = []\n",
    "    for i in range(framesNeeded+1):\n",
    "        index = i*hop_size\n",
    "        frame = paddedSignal[index : index+2048]\n",
    "        framesCustom.append(frame)\n",
    "        \n",
    "    \n",
    "    frames = madmom.audio.signal.FramedSignal(signal)\n",
    "    \n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    for i, sample in enumerate(frames[986]):\n",
    "        samples.append(sample)\n",
    "        \n",
    "    samples.reverse()\n",
    "    \n",
    "    zs = 0\n",
    "    foundNon0 = False;\n",
    "    for j, sample in enumerate(samples):\n",
    "        #print(sample)\n",
    "        if(sample == 0 and not foundNon0):\n",
    "            zs = zs+1\n",
    "        else:\n",
    "            foundNon0 = True\n",
    "    \n",
    "    print(zs)\n",
    "    \n",
    "    print(frames[985][1712])\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\")\n",
    "    print(frames[10])\n",
    "    print(framesCustom[10])\n",
    "    \n",
    "    spectrogram = None\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal length: 435074\n",
      "end zeros: 776\n",
      "padded signal length: 436874\n",
      "\n",
      "[0.00112915 0.00119019 0.00125122 ... 0.00018311 0.00024414 0.00033569]\n",
      "[0.00112915 0.00119019 0.00125122 ... 0.00018311 0.00024414 0.00033569]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texasName = AUDIO_FILES[19] #AUDIO_FILES[19]\n",
    "texasName\n",
    "\n",
    "pre_process(texasName, 2048, 100, 40)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5]\n",
    "a[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
